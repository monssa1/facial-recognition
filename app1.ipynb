{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#import flask\n",
    "import io\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#import flask\n",
    "import io\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "classifier = load_model('C://Users/mdroot/Documents/model/model1.1.h5')\n",
    "list_id = ['0007',\n",
    " '0370',\n",
    " '0371',\n",
    " '0378',\n",
    " '0379',\n",
    " '0382',\n",
    " '0395',\n",
    " '1514',\n",
    " '2282',\n",
    " '2437',\n",
    " '2556',\n",
    " '3340',\n",
    " '3522',\n",
    " '4308',\n",
    " '4364',\n",
    " '4996',\n",
    " '5377',\n",
    " '6142',\n",
    " '6365',\n",
    " '6441',\n",
    " '6685',\n",
    " '6846',\n",
    " '6847',\n",
    " '7407',\n",
    " '7597',\n",
    " '7600',\n",
    " '7667',\n",
    " '7719',\n",
    " '7751',\n",
    " '8038',\n",
    " '8069',\n",
    " '8086',\n",
    " '8135',\n",
    " '8151',\n",
    " '8202',\n",
    " '8312',\n",
    " '8420',\n",
    " '8602',\n",
    " '8859',\n",
    " '8887',\n",
    " '9828']\n",
    "print(len(list_id))\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image  \n",
    "import PIL \n",
    "# lecture du detecteuer  de face de opencv\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#lancer la video depuis le webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "(width, height) = (224, 224)\n",
    "def fonct_pred(imag): \n",
    "    x = np.expand_dims(imag, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    # Try to recognize the face\n",
    "    prediction = classifier.predict(images)\n",
    "    y_pred = np.argmax(prediction, axis=1)\n",
    "    y_pred = y_pred[0]\n",
    "    predt = list_id[y_pred]\n",
    "    return predt\n",
    "    \n",
    "#on boucle pour chaque frame\n",
    "while True :\n",
    "    _, img = cap.read()\n",
    "    picture = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(picture, 1.1, 4,minSize = (224, 224))\n",
    "\n",
    "    #dessiner le rectengle sur l'image\n",
    "    for (x, y, w, h) in faces :\n",
    "        print()\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        face_to_predict = picture[y:y + h, x:x + w]\n",
    "        face_resize = cv2.resize(face_to_predict, (width, height))\n",
    "        ypred = fonct_pred(face_resize)\n",
    "        #img = np.ascontiguousarray(img)\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(img,ypred,(x-10, y-10), cv2.FONT_HERSHEY_SIMPLEX,1,(0, 255, 0))\n",
    "        \n",
    "    cv2.imshow('Camera', img)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #print(face_resize.shape)\n",
    "        x = np.expand_dims(face_resize, axis=0)\n",
    "        images = np.vstack([x])\n",
    "        # Try to recognize the face\n",
    "        prediction = classifier.predict(images)\n",
    "        y_pred = np.argmax(prediction, axis=1)\n",
    "        y_pred = y_pred[0]\n",
    "        print(y_pred)\n",
    "        #result = list_id[y_pred.index(1)]\n",
    "        print(list_id[y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-03c82f513665>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWebcamVideoStream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "from imutils.video import WebcamVideoStream\n",
    "import cv2\n",
    "#import keras\n",
    "import sys,os\n",
    "#sys.path.append(os.path.abspath(\"C://Users/mdroot/Documents/model/model1.1.h5\"))\n",
    "#import tensorflow as tf\n",
    "from keras import models \n",
    "#classifier = tf.keras.models.load_model('C://Users/mdroot/Documents/model/model1.1.h5')\n",
    "\n",
    "list_id = ['0007', '0370', '0371', '0378', '0379', '0382', '0395', '1514', '2282', '2437', '2556', '3340', '3522', '4308', '4364', '4996', '5377', '6142', '6365', '6441', '6685',\n",
    " '6846', '6847', '7407', '7597', '7600', '7667', '7719', '7751', '8038', '8069', '8086', '8135', '8151', '8202', '8312', '8420', '8602', '8859', '8887', '9828']\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "class VideoCamera(object):\n",
    "    def __init__(self):\n",
    "        # Using OpenCV to capture from device 0. If you have trouble capturing\n",
    "        # from a webcam, comment the line below out and use a video file\n",
    "        # instead.\n",
    "\n",
    "        self.stream = WebcamVideoStream(src=0).start()\n",
    "        #with open(\"trained_knn_model.clf\", 'rb') as f:\n",
    "        #    self.knn_clf = pickle.load(f)\n",
    "\n",
    "\n",
    "    def __del__(self):\n",
    "        self.stream.stop()\n",
    "\n",
    "    def fonct_pred(imag):\n",
    "        x = np.expand_dims(imag, axis=0)\n",
    "        images = np.vstack([x])\n",
    "        # Try to recognize the face\n",
    "        prediction = classifier.predict(images)\n",
    "        #print(prediction)\n",
    "        pourcentage = max(prediction[0])\n",
    "        y_pred = np.argmax(prediction, axis=1)\n",
    "        #print(prediction[0])\n",
    "        y_pred = y_pred[0]\n",
    "        predt = list_id[y_pred]\n",
    "        return predt,pourcentage\n",
    "\n",
    "    def predict(self, frame, knn_clf, distance_threshold=0.4):\n",
    "        # Find face locations\n",
    "        #X_face_locations = face_recognition.face_locations(frame)\n",
    "        # print(\"X_face_locations\",X_face_locations[0])\n",
    "        # X_face_locations[0][0]: X_face_locations[0][1], X_face_locations[0][2]: X_face_locations[0][3]\n",
    "        # try:\n",
    "        #     print(\"here\")\n",
    "        #     cv2.imshow(\"fdgd\",frame[57:304,242:118])\n",
    "        #     cv2.waitKey(1)\n",
    "        # except:\n",
    "        #     pass\n",
    "        # If no faces are found in the image, return an empty result.\n",
    "        #if len(X_face_locations) == 0:\n",
    "            return []\n",
    "\n",
    "        # Find encodings for faces in the test iamge\n",
    "        #faces_encodings = face_recognition.face_encodings(frame, known_face_locations=X_face_locations)\n",
    "\n",
    "        # Use the KNN model to find the best matches for the test face\n",
    "        #closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1)\n",
    "        #are_matches = [closest_distances[0][i][0] <= distance_threshold for i in range(len(X_face_locations))]\n",
    "        #for i in range(len(X_face_locations)):\n",
    "         #   print(\"closest_distances\")\n",
    "         #   print(closest_distances[0][i][0])\n",
    "\n",
    "        # Predict classes and remove classifications that aren't within the threshold\n",
    "        #return [(pred, loc) if rec else (\"unknown\", loc) for pred, loc, rec in\n",
    "        #        zip(knn_clf.predict(faces_encodings), X_face_locations, are_matches)]\n",
    "\n",
    "    def get_frame(self):\n",
    "        image = self.stream.read()\n",
    "        li = []\n",
    "        (width, height) = (224, 224)\n",
    "        global person_name\n",
    "        # We are using Motion JPEG, but OpenCV defaults to capture raw images,\n",
    "        # so we must encode it into JPEG in order to correctly display the\n",
    "        #name = ''\n",
    "        detector=cv2.CascadeClassifier('C:/Users/mdroot/Downloads/face-detection-master/face-detection-master/haarcascade_frontalface_default.xml')\n",
    "        faces=detector.detectMultiScale(image,1.1,7)\n",
    "        #[cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2) for (x,y,h,w) in face]\n",
    "        #dessiner le rectengle sur l'image\n",
    "        for (x, y, w, h) in faces :\n",
    "            #cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            face_to_predict = image[y:y + h, x:x + w]\n",
    "            face_resize = cv2.resize(face_to_predict, (width, height))\n",
    "            cv2.rectangle(image, (x, y+5), (x + w+15, y + h+15), (0, 255, 0), 2)\n",
    "        ret, jpeg = cv2.imencode('.jpg', image)\n",
    "        data = []\n",
    "        data.append(jpeg.tobytes())\n",
    "        #data.append(name)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
